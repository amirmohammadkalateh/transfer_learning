# Transfer Learning Example: Cat vs. Dog Classification

This repository demonstrates the use of transfer learning for image classification, specifically distinguishing between cats and dogs, using a pre-trained ResNet-50 model.

## Overview

Transfer learning is a powerful technique in machine learning, particularly in deep learning, where a model trained on one task is reused as a starting point for a model on a second, related task. This project applies transfer learning to a computer vision scenario, leveraging the pre-trained ResNet-50 model to build a cat vs. dog classifier with a limited dataset.

## General Steps of Transfer Learning

1.  **Select a Pre-trained Model:**
    * Choose a model trained on a large dataset relevant to your target task. For image recognition, models like VGG, ResNet, or EfficientNet, trained on ImageNet, are common.
    * These models have learned hierarchical feature representations: early layers detect basic features (edges, textures), and later layers detect more complex features (object parts, whole objects).

2.  **Modify the Model:**
    * Replace the final classification layer(s) of the pre-trained model with new layers suitable for your specific task.
    * Example: Replace the 1000-class output layer of ImageNet-trained ResNet-50 with a 2-class output layer (cat vs. dog).

3.  **Freeze Layers (Optional):**
    * Prevent the weights of early layers from being updated during training.
    * This is useful for preserving general feature detectors and preventing overfitting, especially with small datasets.

4.  **Train the Modified Model:**
    * Train the new, modified model on your target dataset.
    * Typically, train only the newly added layers or a few of the top layers, keeping the frozen layers unchanged.

5.  **Fine-tuning (Optional):**
    * After training the new layers, unfreeze some of the earlier layers and continue training with a very low learning rate.
    * This allows the pre-trained features to adapt slightly to your target dataset, potentially improving performance.

## Cat vs. Dog Classification Example

### Scenario

Build a classifier to distinguish between images of cats and dogs using a limited dataset.

### Steps

1.  **Select a Pre-trained Model:**
    * Use a pre-trained ResNet-50 model, trained on ImageNet.

2.  **Modify the Model:**
    * Remove the final fully connected layer of ResNet-50 (1000 classes).
    * Add a new fully connected layer with 2 output neurons and a softmax activation function.

3.  **Freeze Layers:**
    * Freeze the convolutional layers of ResNet-50, keeping only the new fully connected layer trainable.

4.  **Train the Modified Model:**
    * Train the model on your cat vs. dog dataset.
    * Use a small learning rate and categorical cross-entropy loss.

5.  **Fine-tuning (Optional):**
    * After training the final layer, unfreeze the last few convolutional layers of ResNet-50.
    * Continue training the entire model with a very low learning rate.

## Key Considerations

* **Similarity of Tasks:** Transfer learning works best when the source and target tasks are similar.
* **Dataset Size:** Transfer learning is particularly beneficial with small target datasets.
* **Computational Resources:** Using a pre-trained model reduces training time and computational resources.

## Usage

1.  **Dependencies:**
    * Install TensorFlow: `pip install tensorflow`

2.  **Data Organization:**
    * Organize your cat and dog images into `train` and `validation` directories, each containing `cats` and `dogs` subdirectories.
    ```
    data/
    ├── train/
    │   ├── cats/
    │   └── dogs/
    └── validation/
        ├── cats/
        └── dogs/
    ```

3.  **Run the Code:**
    * Execute the provided Python script (e.g., `python cat_dog_classifier.py`).
    * Modify the script to point to your data directories.

4.  **Model Saving:**
    * The trained model will be saved as `cat_dog_classifier.h5`.

## Code Example

See the `cat_dog_classifier.py` file for the implementation details.
import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

# 1. Load the pre-trained model (ResNet50)
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# 2. Modify the model
x = base_model.output
x = GlobalAveragePooling2D()(x) # Global average pooling to reduce dimensions
x = Dense(1024, activation='relu')(x) # Add a dense layer
predictions = Dense(2, activation='softmax')(x) # Output layer for 2 classes (cat/dog)

model = Model(inputs=base_model.input, outputs=predictions)

# 3. Freeze layers
for layer in base_model.layers:
    layer.trainable = False

# 4. Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Data Preparation (Example using ImageDataGenerator)
# Assuming you have 'train' and 'validation' directories with cat/dog subdirectories

train_datagen = ImageDataGenerator(rescale=1./255,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True)

validation_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    'train',  # Replace with your training data directory
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical')

validation_generator = validation_datagen.flow_from_directory(
    'validation', # Replace with your validation data directory
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical')

# 5. Train the model
model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // 32,
    epochs=10, # Adjust epochs as needed
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // 32)

# 6. Fine-tuning (Optional)
# Unfreeze some layers and continue training with a lower learning rate

for layer in model.layers[140:]: #unfreeze last few layers, you may need to experiment.
    layer.trainable = True

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), #very low learning rate
              loss='categorical_crossentropy', metrics=['accuracy'])

model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // 32,
    epochs=5, # Fine-tune for a few epochs
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // 32)

# Save the model
model.save("cat_dog_classifier.h5")





